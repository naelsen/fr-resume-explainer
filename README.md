# fr-resume-explainer

_Ce projet est en cours de d√©veloppement, et je mettrai r√©guli√®rement √† jour ce README.md avec les avanc√©es du projet._

Ce projet vise √† classer les CV en fonction de leur comp√©tence en Data Science. Pour cela, j'ai construis une base de donn√©es en scrappant les offres d'emploie Indeed que j'ai valoris√© avec GPT-3. En outre, j'ai utilis√© l'architecture BERT (bert-base-multilingual-cased) et les Adapters de la librairie `adapter-transformers` pour construire en entra√Æner mon mod√®le.

## Installation

`fr-resume-explainer` supporte **Python 3.8+**.

_Important üí° : Assurez-vous de cr√©er un nouvel environnement Python 3.8+ avant de commencer._

```
git clone https://github.com/naelsen/fr-resume-explainer.git
cd fr-resume-explainer
pip install -r requirements.txt
```
## Comment construire votre Dataset ?

### 1) [G√©n√©rer une clef API OpenAI](https://platform.openai.com/account/api-keys).

### 2) Par s√©curit√©, stocker cette clef dans une variable d'environnement :

- Ouvrez le fichier cach√© bashrc avec votre √©diteur de texte pr√©f√©r√©, par exemple :

```
gedit ~/.bashrc
```

- Ajouter cette ligne dans le fichier

```
export OPENAI_API_KEY=<YOUR_KEY>
```

- Vous pouvez maintenant modifer le fichier `build_dataset.py` pour mettre plusieurs clefs si vous disposez de plusieurs compte OpenAPI. Il est important que chaque compte dispose d'un num√©ro de t√©l√©phone unique pour disposer des 18$ de jeton gratuit. Ensuite taper la commande suivante dans votre terminal :

```
python3 build_dataset.py
```

## Comment construire le mod√®le ?

Vous pouvez lancer la commande suivante :
```
python3 build_adapter-bert-based.py 
```

## Architecture du mod√®le

J'ai utilis√© l'impl√©mentation de BERT dans les librairies transformer et adapter-transformers pour construire le mod√®le. J'ai fine-tun√© le mod√®le BERT-base-multilingual-cased en ajoutant un adapter et une t√™te de classification au  mod√®le BERT. Les Adapters sont l'√©tat de l'art en Transfert Learning, ce sont des r√©seaux neuronaux qui peuvent √™tre ajout√©s √† une architecture de mod√®le pr√©-entra√Æn√©, dans notre cas √† BERT. Ils introduisent une petite quantit√© de nouveaux param√®tres Œ¶ dans le mod√®le pr√©-entra√Æn√© avec des param√®tres Œò existants. Les param√®tres Œ¶ sont entra√Ænable pour une t√¢che sp√©cifique tout en conservant Œò fixe, de sorte qu'ils apprennent √† encoder des repr√©sentations sp√©cifiques √† la t√¢che dans les couches interm√©diaires du mod√®le pr√©-entra√Æn√©.

## √âvaluation du mod√®le

Le mod√®le a √©t√© enta√Æn√© pour minimiser la fonction d'entropie crois√©e de l'ensemble d'entra√Ænement et a √©t√© √©valu√© sur l'ensemble maximisant la m√©trique F1 sur un ensemble de validation.

![evaluation](https://github.com/naelsen/fr-resume-explainer/blob/main/tensorBoard.png)

## Interpr√©tation des r√©sultats

Pour interpr√©ter les pr√©dictions du mod√®le, je vais utiliser la m√©thode d'√©stimation des valeurs de shapley. Cette m√©thode se base sur la th√©orie des jeux pour estimer l'importance de chaque feature pour chaque pr√©diction du mod√®le. Les valeurs de shapley permettent ainsi d'expliquer les d√©cisions prises par le mod√®le et d'identifier les features les plus importantes pour la t√¢che de classification.

